# -*- coding: utf-8 -*-
"""trainmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vOY8uKhUoDyAfeq5pTtrzGarNueilrls

Part A: Train model
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib

# Sample training data
data = [
    ("What is the Pythagorean theorem?", "Math"),
    ("How do you solve a quadratic equation?", "Math"),
    ("What is the formula for area of a circle?", "Math"),
    ("What is gravity?", "Science"),
    ("Explain photosynthesis", "Science"),
    ("What is an atom?", "Science"),
    ("Define a noun", "English"),
    ("How to write an essay?", "English"),
    ("What is a verb?", "English")
]

X, y = zip(*data)

# Vectorizer and Model
vectorizer = TfidfVectorizer()
X_vectorized = vectorizer.fit_transform(X)

model = LogisticRegression()
model.fit(X_vectorized, y)

# Save both model and vectorizer
joblib.dump(model, "model.joblib")
joblib.dump(vectorizer, "vectorizer.joblib")

print("Model and vectorizer saved.")

"""Part B: Flask API with ML Model"""

from flask import Flask, request, jsonify
import joblib
import json
import os

app = Flask(__name__)

MODEL_PATH = 'model.joblib'
VECTORIZER_PATH = 'vectorizer.joblib'
LOG_FILE = 'questions.json'

# Load ML model and vectorizer
model = joblib.load(MODEL_PATH)
vectorizer = joblib.load(VECTORIZER_PATH)

# Load existing log
if not os.path.exists(LOG_FILE):
    with open(LOG_FILE, 'w') as f:
        json.dump([], f)

@app.route('/classify-question', methods=['POST'])
def classify():
    try:
        data = request.get_json()
        if not data or 'question' not in data:
            return jsonify({'error': "Missing 'question' in input"}), 400

        question = data['question']
        if not isinstance(question, str) or not question.strip():
            return jsonify({"error": "'question' must be a non-empty string"}), 400

        vector = vectorizer.transform([question])
        prediction = model.predict(vector)[0]
        confidence = max(model.predict_proba(vector)[0])

        result = {
            "question": question,
            "topic": prediction,
            "confidence": round(confidence, 2)
        }

        with open(LOG_FILE, 'r+') as f:
            history = json.load(f)
            history.append(result)
            f.seek(0)
            json.dump(history, f, indent=2)

        return jsonify({"topic": prediction, "confidence": round(confidence, 2)}), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/questions', methods=['GET'])
def get_questions():
    try:
        with open(LOG_FILE, 'r') as f:
            history = json.load(f)
        return jsonify(history), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

#Test with curl:
curl -X POST http://127.0.0.1:5000/classify-question \
-H "Content-Type: application/json" \
-d '{"question": "What is an atom?"}'

"""Get logged questions:"""

curl http://127.0.0.1:5000/questions